{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enron email sender classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from spacy import load\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "from statistics import stdev\n",
    "#import features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data from the csv file to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\faraa\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>file_id</th>\n",
       "      <th>msg</th>\n",
       "      <th>Message-ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Mime-Version</th>\n",
       "      <th>...</th>\n",
       "      <th>Content-Transfer-Encoding</th>\n",
       "      <th>X-From</th>\n",
       "      <th>X-To</th>\n",
       "      <th>X-cc</th>\n",
       "      <th>X-bcc</th>\n",
       "      <th>X-Folder</th>\n",
       "      <th>X-Origin</th>\n",
       "      <th>X-FileName</th>\n",
       "      <th>content</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>lokay-m/lokay-m_65/</td>\n",
       "      <td>Message-ID: &lt;11819236.1075844017427.JavaMail.e...</td>\n",
       "      <td>&lt;11819236.1075844017427.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Wed, 14 Jun 2000 01:24:00 -0700 (PDT)</td>\n",
       "      <td>frozenset({'steven.harris@enron.com'})</td>\n",
       "      <td>frozenset({'michele.lokay@enron.com'})</td>\n",
       "      <td>Reminder: WEFA Meeting Tomorrow Morning, June ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Steven Harris</td>\n",
       "      <td>Michele Lokay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\Michelle_Lokay_Dec2000_June2001_1\\Notes Folde...</td>\n",
       "      <td>LOKAY-M</td>\n",
       "      <td>mlokay.nsf</td>\n",
       "      <td>FYI\\n---------------------- Forwarded by Steve...</td>\n",
       "      <td>lokay-m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1              file_id  \\\n",
       "0           0             0  lokay-m/lokay-m_65/   \n",
       "\n",
       "                                                 msg  \\\n",
       "0  Message-ID: <11819236.1075844017427.JavaMail.e...   \n",
       "\n",
       "                                      Message-ID  \\\n",
       "0  <11819236.1075844017427.JavaMail.evans@thyme>   \n",
       "\n",
       "                                    Date  \\\n",
       "0  Wed, 14 Jun 2000 01:24:00 -0700 (PDT)   \n",
       "\n",
       "                                     From  \\\n",
       "0  frozenset({'steven.harris@enron.com'})   \n",
       "\n",
       "                                       To  \\\n",
       "0  frozenset({'michele.lokay@enron.com'})   \n",
       "\n",
       "                                             Subject  Mime-Version  ...  \\\n",
       "0  Reminder: WEFA Meeting Tomorrow Morning, June ...           1.0  ...   \n",
       "\n",
       "  Content-Transfer-Encoding         X-From           X-To X-cc X-bcc  \\\n",
       "0                      7bit  Steven Harris  Michele Lokay  NaN   NaN   \n",
       "\n",
       "                                            X-Folder X-Origin  X-FileName  \\\n",
       "0  \\Michelle_Lokay_Dec2000_June2001_1\\Notes Folde...  LOKAY-M  mlokay.nsf   \n",
       "\n",
       "                                             content     user  \n",
       "0  FYI\\n---------------------- Forwarded by Steve...  lokay-m  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_df = pd.read_csv('extracted-2.csv')\n",
    "emails_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a sample of 2000 emails randomly from each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = emails_df[[\"Message-ID\", \"content\", \"user\"]].groupby('user').apply(lambda df: df.sample(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample[\"doc\"] = df_sample.content.apply(load('en'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting character based features from each email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_characters = pd.DataFrame()\n",
    "    \n",
    "for index, row in df_sample.iterrows():    \n",
    "    num_chars = 0\n",
    "    num_letters = 0\n",
    "    num_upper_case = 0\n",
    "    num_lower_case = 0\n",
    "    num_punctuation = 0\n",
    "    num_spaces = 0\n",
    "    num_nums = 0\n",
    "    \n",
    "    for word in row['doc']:\n",
    "        for char in str(word):\n",
    "            num_chars += 1\n",
    "            if char.isalpha():\n",
    "                num_letters += 1\n",
    "            if char.isupper():\n",
    "                num_upper_case += 1\n",
    "            if char.islower():\n",
    "                num_lower_case += 1\n",
    "            if char in punctuation:\n",
    "                num_punctuation += 1\n",
    "            if char.isspace():\n",
    "                num_spaces += 1\n",
    "            if char.isnumeric():\n",
    "                num_nums += 1\n",
    "            \n",
    "    df_row = pd.DataFrame({\"chars\": num_chars, \"letters\": num_letters, \"upper_case\": num_upper_case, \"lower_case\": num_lower_case, \"punctuations\": num_punctuation, \"spaces\": num_spaces, \"nums\": num_nums}, index=[0])\n",
    "    df_characters = df_characters.append(df_row, ignore_index=True)\n",
    "\n",
    "df_sample['temp'] = \"\"\n",
    "df_characters['temp'] = 1\n",
    "\n",
    "for i in range(df_sample['user'].count()):\n",
    "    df_sample['temp'][i] = i\n",
    "    df_characters['temp'][i] = i\n",
    "    \n",
    "df_sample = pd.merge(df_sample, df_characters, on=['temp'])\n",
    "#df_sample = df_sample.drop('temp', axis=1)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting word based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\faraa\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df_words = pd.DataFrame()\n",
    "\n",
    "for index, row in df_sample.iterrows():\n",
    "    long_word = 5\n",
    "    num_words = 0\n",
    "    avg_letters_per_word = 0\n",
    "    num_longwords = 0\n",
    "    num_stopwords = 0\n",
    "    num_error = 0\n",
    "    TTR = 0\n",
    "    hapaxes = []\n",
    "    HTR = 0\n",
    "    word_list = []\n",
    "    sorted_word_frequency = []\n",
    "    max_frequency = 0\n",
    "    \n",
    "    for word in row['doc']:\n",
    "        if word.is_alpha:\n",
    "            num_words += 1\n",
    "            if len(word) > long_word:\n",
    "                num_longwords += 1\n",
    "            if word.is_stop:\n",
    "                num_stopwords += 1\n",
    "            if not word.vocab:\n",
    "                num_error += 1\n",
    "            word_list.append(str(word))\n",
    "    \n",
    "    if num_words > 0:\n",
    "        avg_letters_per_word = float(row['letters']/num_words)\n",
    "    else:\n",
    "        avg_letters_per_word = 0\n",
    "    \n",
    "    if len(word_list) > 0:\n",
    "        TTR = len(set(word_list))/len(word_list)\n",
    "        hapaxes = list(filter(lambda x: word_list.count(x) == 1, word_list))\n",
    "        HTR = len(hapaxes)/len(word_list)\n",
    "        sorted_word_frequency = sorted(Counter(word_list).items(), key=itemgetter(1), reverse=True)\n",
    "        max_frequency = sorted_word_frequency[0][1]\n",
    "        \n",
    "    df_row = pd.DataFrame({\"words\": num_words, \"avg_letters_per_word\": avg_letters_per_word, \"longwords\": num_longwords, \"stopwords\": num_stopwords, \"spelling_errors\": num_error, \"TTR\": TTR, \"HTR\": HTR, \"max_frequency\": max_frequency}, index=[0])\n",
    "    df_words = df_words.append(df_row, ignore_index=True)\n",
    "\n",
    "df_words['temp'] = 1\n",
    "\n",
    "for i in range(df_sample['user'].count()):\n",
    "    df_words['temp'][i] = i\n",
    "    \n",
    "df_sample = pd.merge(df_sample, df_words, on=['temp'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting sentence based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\faraa\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df_sentences = pd.DataFrame()\n",
    "\n",
    "for index, row in df_sample.iterrows():\n",
    "    sentences = list(row['doc'].sents)\n",
    "    num_sentences = len(sentences)\n",
    "    \n",
    "    #nr_words_l = [len(s) for s in doc.sents]\n",
    "    avg_num_words_per_sentence = row['words']/num_sentences\n",
    "    \n",
    "    if len(sentences) > 1:\n",
    "        std_num_words_per_sentence = stdev([len(sentence) for sentence in sentences])\n",
    "    else:\n",
    "        std_nr_word_per_sent = 0\n",
    "\n",
    "    df_row = pd.DataFrame({\"sentences\": num_sentences, \"avg_num_words_per_sentence\": avg_num_words_per_sentence, \"std_num_words_per_sentence\": std_num_words_per_sentence}, index=[0])\n",
    "    df_sentences = df_sentences.append(df_row, ignore_index=True)\n",
    "    \n",
    "df_sentences['temp'] = 1\n",
    "\n",
    "for i in range(df_sample['user'].count()):\n",
    "    df_sentences['temp'][i] = i\n",
    "    \n",
    "df_sample = pd.merge(df_sample, df_sentences, on=['temp'])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting punctuation based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_punctuations = pd.DataFrame()\n",
    "\n",
    "for index, row in df_sample.iterrows():\n",
    "    num_dots = 0\n",
    "    num_commas = 0\n",
    "    num_question_marks = 0\n",
    "    num_exclamations = 0\n",
    "    num_hyphens = 0\n",
    "    num_colons = 0\n",
    "    num_semicolons = 0\n",
    "    \n",
    "    for word in row['doc']:\n",
    "        if str(word) == \".\":\n",
    "            num_dots += 1\n",
    "        if str(word) == \",\":\n",
    "            num_commas += 1\n",
    "        if str(word) == \"?\":\n",
    "            num_question_marks += 1\n",
    "        if str(word) == \"!\":\n",
    "            num_exclamations += 1\n",
    "        if str(word) == \"-\":\n",
    "            num_hyphens += 1\n",
    "        if str(word) == \":\":\n",
    "            num_colons += 1\n",
    "        if str(word) == \";\":\n",
    "            num_semicolons += 1\n",
    "        \n",
    "    df_row = pd.DataFrame({\"dots\": num_dots, \"commas\": num_commas, \"question_marks\": num_question_marks, \"exclamations\": num_exclamations, \"hyphens\": num_hyphens, \"colons\": num_colons, \"semicolons\": num_semicolons}, index=[0])\n",
    "    df_punctuations = df_punctuations.append(df_row, ignore_index=True)\n",
    "    \n",
    "df_punctuations['temp'] = 1\n",
    "\n",
    "for i in range(df_sample['user'].count()):\n",
    "    df_punctuations['temp'][i] = i\n",
    "    \n",
    "df_sample = pd.merge(df_sample, df_punctuations, on=['temp'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting paragraph based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\faraa\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df_paragraphs = pd.DataFrame()\n",
    "\n",
    "for index, row in df_sample.iterrows():\n",
    "    sum_sent = 0\n",
    "    av_sent = 0\n",
    "    sum_word = 0\n",
    "    av_word = 0\n",
    "\n",
    "    paragraphs = row['content'].split('\\n\\n')\n",
    "    paragraphs = [paragraph for paragraph in paragraphs if not (paragraph.isspace()or paragraph == \"\")]\n",
    "#     for paragraph in paragraphs:\n",
    "#         sentences = re.split('[?!.\\n]', paragraph)\n",
    "#         sentences = [sentence for sentence in sentences if not (sentence.isspace()or sentence == \"\")]\n",
    "#         sum_sent += len(sentences)\n",
    "#         for sentence in sentences:\n",
    "#             words = sentence.split(\" \")\n",
    "#             words = [word for word in words if not (word.isspace()or word == \"\")]\n",
    "#             sum_word += len(words)\n",
    "    av_sent = row['sentences'] / len(paragraphs)\n",
    "    av_word = row['words'] / len(paragraphs)\n",
    "\n",
    "    df_row = pd.DataFrame({\"n_paragraphs\": len(paragraphs), \"av_sent\": av_sent, \"av_word\": av_word}, index=[0])\n",
    "    df_paragraphs = df_paragraphs.append(df_row, ignore_index=True)\n",
    "\n",
    "df_paragraphs['temp'] = 1\n",
    "\n",
    "for i in range(df_sample['user'].count()):\n",
    "    df_paragraphs['temp'][i] = i\n",
    "    \n",
    "df_sample = pd.merge(df_sample, df_paragraphs, on=['temp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      Message-ID  \\\n",
      "0  <17342137.1075852710363.JavaMail.evans@thyme>   \n",
      "1  <23603725.1075857640286.JavaMail.evans@thyme>   \n",
      "2  <12889945.1075857632396.JavaMail.evans@thyme>   \n",
      "3  <28178420.1075861673628.JavaMail.evans@thyme>   \n",
      "4   <4799329.1075857598592.JavaMail.evans@thyme>   \n",
      "\n",
      "                                             content      user  \\\n",
      "0  \\n\\n\\nmost bullish thing at this point is movi...  arnold-j   \n",
      "1  Gentlemen:\\nThe following champagne is availab...  arnold-j   \n",
      "2  no crap, what's your bid?\\n\\n\\n\\n\\n\"Eva Pao\" <...  arnold-j   \n",
      "3  We just finished doing the xpit that they aske...  arnold-j   \n",
      "4  How about 4:00?\\n\\n\\n\\n\\nSarah Wesner@ENRON\\n0...  arnold-j   \n",
      "\n",
      "                                                 doc temp  chars  letters  \\\n",
      "0  (\\n\\n\\n, most, bullish, thing, at, this, point...    0    526      487   \n",
      "1  (Gentlemen, :, \\n, The, following, champagne, ...    1    530      401   \n",
      "2  (no, crap, ,, what, 's, your, bid, ?, \\n\\n\\n\\n...    2   3517     2939   \n",
      "3  (We, just, finished, doing, the, xpit, that, t...    3    683      607   \n",
      "4  (How, about, 4:00, ?, \\n\\n\\n\\n\\n, Sarah, Wesne...    4    211      163   \n",
      "\n",
      "   upper_case  lower_case  punctuations  ...  dots  commas  question_marks  \\\n",
      "0           0         487            16  ...     6       1               1   \n",
      "1          35         366            10  ...     4       0               2   \n",
      "2         140        2799           262  ...    24      34               4   \n",
      "3          38         569            31  ...     7       5               1   \n",
      "4          28         135            17  ...     1       0               2   \n",
      "\n",
      "   exclamations  hyphens  colons  semicolons  n_paragraphs   av_sent  \\\n",
      "0             0        0       0           0             1  8.000000   \n",
      "1             0        0       1           0             3  4.333333   \n",
      "2             0        1      21           0            21  3.333333   \n",
      "3             0        1       4           0             4  3.250000   \n",
      "4             0        1       3           0             3  3.333333   \n",
      "\n",
      "      av_word  \n",
      "0  109.000000  \n",
      "1   22.333333  \n",
      "2   28.571429  \n",
      "3   33.750000  \n",
      "4   11.666667  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "print (df_sample.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
