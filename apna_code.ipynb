{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enron email sender classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from spacy import load\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "from statistics import stdev\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import label_binarize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data from the csv file to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\faraa\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>file_id</th>\n",
       "      <th>msg</th>\n",
       "      <th>Message-ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Mime-Version</th>\n",
       "      <th>...</th>\n",
       "      <th>Content-Transfer-Encoding</th>\n",
       "      <th>X-From</th>\n",
       "      <th>X-To</th>\n",
       "      <th>X-cc</th>\n",
       "      <th>X-bcc</th>\n",
       "      <th>X-Folder</th>\n",
       "      <th>X-Origin</th>\n",
       "      <th>X-FileName</th>\n",
       "      <th>content</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>lokay-m/lokay-m_65/</td>\n",
       "      <td>Message-ID: &lt;11819236.1075844017427.JavaMail.e...</td>\n",
       "      <td>&lt;11819236.1075844017427.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Wed, 14 Jun 2000 01:24:00 -0700 (PDT)</td>\n",
       "      <td>frozenset({'steven.harris@enron.com'})</td>\n",
       "      <td>frozenset({'michele.lokay@enron.com'})</td>\n",
       "      <td>Reminder: WEFA Meeting Tomorrow Morning, June ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Steven Harris</td>\n",
       "      <td>Michele Lokay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\Michelle_Lokay_Dec2000_June2001_1\\Notes Folde...</td>\n",
       "      <td>LOKAY-M</td>\n",
       "      <td>mlokay.nsf</td>\n",
       "      <td>FYI\\n---------------------- Forwarded by Steve...</td>\n",
       "      <td>lokay-m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1              file_id  \\\n",
       "0           0             0  lokay-m/lokay-m_65/   \n",
       "\n",
       "                                                 msg  \\\n",
       "0  Message-ID: <11819236.1075844017427.JavaMail.e...   \n",
       "\n",
       "                                      Message-ID  \\\n",
       "0  <11819236.1075844017427.JavaMail.evans@thyme>   \n",
       "\n",
       "                                    Date  \\\n",
       "0  Wed, 14 Jun 2000 01:24:00 -0700 (PDT)   \n",
       "\n",
       "                                     From  \\\n",
       "0  frozenset({'steven.harris@enron.com'})   \n",
       "\n",
       "                                       To  \\\n",
       "0  frozenset({'michele.lokay@enron.com'})   \n",
       "\n",
       "                                             Subject  Mime-Version  ...  \\\n",
       "0  Reminder: WEFA Meeting Tomorrow Morning, June ...           1.0  ...   \n",
       "\n",
       "  Content-Transfer-Encoding         X-From           X-To X-cc X-bcc  \\\n",
       "0                      7bit  Steven Harris  Michele Lokay  NaN   NaN   \n",
       "\n",
       "                                            X-Folder X-Origin  X-FileName  \\\n",
       "0  \\Michelle_Lokay_Dec2000_June2001_1\\Notes Folde...  LOKAY-M  mlokay.nsf   \n",
       "\n",
       "                                             content     user  \n",
       "0  FYI\\n---------------------- Forwarded by Steve...  lokay-m  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_df = pd.read_csv('extracted-2.csv')\n",
    "emails_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a sample of 2000 emails randomly from each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = emails_df[[\"Message-ID\", \"content\", \"user\"]].groupby('user').apply(lambda df: df.sample(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample[\"doc\"] = df_sample.content.apply(load('en'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting character based features from each email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_characters = pd.DataFrame()\n",
    "    \n",
    "for index, row in df_sample.iterrows():    \n",
    "    num_chars = 0\n",
    "    num_letters = 0\n",
    "    num_upper_case = 0\n",
    "    num_lower_case = 0\n",
    "    num_punctuation = 0\n",
    "    num_spaces = 0\n",
    "    num_nums = 0\n",
    "    \n",
    "    for word in row['doc']:\n",
    "        for char in str(word):\n",
    "            num_chars += 1\n",
    "            if char.isalpha():\n",
    "                num_letters += 1\n",
    "            if char.isupper():\n",
    "                num_upper_case += 1\n",
    "            if char.islower():\n",
    "                num_lower_case += 1\n",
    "            if char in punctuation:\n",
    "                num_punctuation += 1\n",
    "            if char.isspace():\n",
    "                num_spaces += 1\n",
    "            if char.isnumeric():\n",
    "                num_nums += 1\n",
    "            \n",
    "    df_row = pd.DataFrame({\"chars\": num_chars, \"letters\": num_letters, \"upper_case\": num_upper_case, \"lower_case\": num_lower_case, \"punctuations\": num_punctuation, \"spaces\": num_spaces, \"nums\": num_nums}, index=[0])\n",
    "    df_characters = df_characters.append(df_row, ignore_index=True)\n",
    "\n",
    "df_sample['temp'] = \"\"\n",
    "df_characters['temp'] = 1\n",
    "\n",
    "for i in range(df_sample['user'].count()):\n",
    "    df_sample['temp'][i] = i\n",
    "    df_characters['temp'][i] = i\n",
    "    \n",
    "df_sample = pd.merge(df_sample, df_characters, on=['temp'])  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting word based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\faraa\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df_words = pd.DataFrame()\n",
    "\n",
    "for index, row in df_sample.iterrows():\n",
    "    long_word = 5\n",
    "    num_words = 0\n",
    "    avg_letters_per_word = 0\n",
    "    num_longwords = 0\n",
    "    num_stopwords = 0\n",
    "    num_error = 0\n",
    "    TTR = 0\n",
    "    hapaxes = []\n",
    "    HTR = 0\n",
    "    word_list = []\n",
    "    sorted_word_frequency = []\n",
    "    max_frequency = 0\n",
    "    \n",
    "    for word in row['doc']:\n",
    "        if word.is_alpha:\n",
    "            num_words += 1\n",
    "            if len(word) > long_word:\n",
    "                num_longwords += 1\n",
    "            if word.is_stop:\n",
    "                num_stopwords += 1\n",
    "            word_list.append(str(word))\n",
    "    \n",
    "    if num_words > 0:\n",
    "        avg_letters_per_word = float(row['letters']/num_words)\n",
    "    else:\n",
    "        avg_letters_per_word = 0\n",
    "    \n",
    "    if len(word_list) > 0:\n",
    "        TTR = len(set(word_list))/len(word_list)\n",
    "        hapaxes = list(filter(lambda x: word_list.count(x) == 1, word_list))\n",
    "        HTR = len(hapaxes)/len(word_list)\n",
    "        sorted_word_frequency = sorted(Counter(word_list).items(), key=itemgetter(1), reverse=True)\n",
    "        max_frequency = sorted_word_frequency[0][1]\n",
    "        \n",
    "    df_row = pd.DataFrame({\"words\": num_words, \"avg_letters_per_word\": avg_letters_per_word, \"longwords\": num_longwords, \"stopwords\": num_stopwords, \"TTR\": TTR, \"HTR\": HTR, \"max_frequency\": max_frequency}, index=[0])\n",
    "    df_words = df_words.append(df_row, ignore_index=True)\n",
    "\n",
    "df_words['temp'] = 1\n",
    "\n",
    "for i in range(df_sample['user'].count()):\n",
    "    df_words['temp'][i] = i\n",
    "    \n",
    "df_sample = pd.merge(df_sample, df_words, on=['temp'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting sentence based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\faraa\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df_sentences = pd.DataFrame()\n",
    "\n",
    "for index, row in df_sample.iterrows():\n",
    "    sentences = list(row['doc'].sents)\n",
    "    num_sentences = len(sentences)\n",
    "    \n",
    "    #nr_words_l = [len(s) for s in doc.sents]\n",
    "    avg_num_words_per_sentence = row['words']/num_sentences\n",
    "    \n",
    "    if len(sentences) > 1:\n",
    "        std_num_words_per_sentence = stdev([len(sentence) for sentence in sentences])\n",
    "    else:\n",
    "        std_nr_word_per_sent = 0\n",
    "\n",
    "    df_row = pd.DataFrame({\"sentences\": num_sentences, \"avg_num_words_per_sentence\": avg_num_words_per_sentence, \"std_num_words_per_sentence\": std_num_words_per_sentence}, index=[0])\n",
    "    df_sentences = df_sentences.append(df_row, ignore_index=True)\n",
    "    \n",
    "df_sentences['temp'] = 1\n",
    "\n",
    "for i in range(df_sample['user'].count()):\n",
    "    df_sentences['temp'][i] = i\n",
    "    \n",
    "df_sample = pd.merge(df_sample, df_sentences, on=['temp'])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting punctuation based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_punctuations = pd.DataFrame()\n",
    "\n",
    "for index, row in df_sample.iterrows():\n",
    "    num_dots = 0\n",
    "    num_commas = 0\n",
    "    num_question_marks = 0\n",
    "    num_exclamations = 0\n",
    "    num_hyphens = 0\n",
    "    num_colons = 0\n",
    "    num_semicolons = 0\n",
    "    \n",
    "    for word in row['doc']:\n",
    "        if str(word) == \".\":\n",
    "            num_dots += 1\n",
    "        if str(word) == \",\":\n",
    "            num_commas += 1\n",
    "        if str(word) == \"?\":\n",
    "            num_question_marks += 1\n",
    "        if str(word) == \"!\":\n",
    "            num_exclamations += 1\n",
    "        if str(word) == \"-\":\n",
    "            num_hyphens += 1\n",
    "        if str(word) == \":\":\n",
    "            num_colons += 1\n",
    "        if str(word) == \";\":\n",
    "            num_semicolons += 1\n",
    "        \n",
    "    df_row = pd.DataFrame({\"dots\": num_dots, \"commas\": num_commas, \"question_marks\": num_question_marks, \"exclamations\": num_exclamations, \"hyphens\": num_hyphens, \"colons\": num_colons, \"semicolons\": num_semicolons}, index=[0])\n",
    "    df_punctuations = df_punctuations.append(df_row, ignore_index=True)\n",
    "    \n",
    "df_punctuations['temp'] = 1\n",
    "\n",
    "for i in range(df_sample['user'].count()):\n",
    "    df_punctuations['temp'][i] = i\n",
    "    \n",
    "df_sample = pd.merge(df_sample, df_punctuations, on=['temp'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting paragraph based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\faraa\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df_paragraphs = pd.DataFrame()\n",
    "\n",
    "for index, row in df_sample.iterrows():\n",
    "    avg_sentences_per_para = 0\n",
    "    avg_words_per_para = 0\n",
    "\n",
    "    paragraphs = row['content'].split('\\n\\n')\n",
    "    paragraphs = [paragraph for paragraph in paragraphs if not (paragraph.isspace()or paragraph == \"\")]\n",
    "    \n",
    "    avg_sentences_per_para = row['sentences']/len(paragraphs)\n",
    "    avg_words_per_para = row['words']/len(paragraphs)\n",
    "\n",
    "    df_row = pd.DataFrame({\"paragraphs\": len(paragraphs), \"avg_sentences_per_paragrapgh\": avg_sentences_per_para, \"avg_words_per_paragraph\": avg_words_per_para}, index=[0])\n",
    "    df_paragraphs = df_paragraphs.append(df_row, ignore_index=True)\n",
    "\n",
    "df_paragraphs['temp'] = 1\n",
    "\n",
    "for i in range(df_sample['user'].count()):\n",
    "    df_paragraphs['temp'][i] = i\n",
    "    \n",
    "df_sample = pd.merge(df_sample, df_paragraphs, on=['temp'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting semantic based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\faraa\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df_semantics = pd.DataFrame()\n",
    "\n",
    "for index, row in df_sample.iterrows():\n",
    "    intensity = SentimentIntensityAnalyzer()\n",
    "    num_positive_words = 0\n",
    "    num_negative_words = 0\n",
    "    num_named_entities = 0\n",
    "\n",
    "    for word in row['doc']:\n",
    "        if (intensity.polarity_scores(str(word))['compound']) >= 0.5:\n",
    "            num_positive_words += 1\n",
    "        elif (intensity.polarity_scores(str(word))['compound']) <= -0.5:\n",
    "            num_negative_words += 1\n",
    "        \n",
    "        if word.ent_type_ != \"\":\n",
    "            num_named_entities += 1       \n",
    "    \n",
    "    score = intensity.polarity_scores(row['content'])['compound']\n",
    "    greeting_words_list = [\"Dear\", \"To Whom It May Concern\", \"Hello\", \"Hi\"]\n",
    "    num_greeting_words = 0\n",
    "    for g_word in row['content'].split():\n",
    "        if g_word in greeting_words_list:\n",
    "            num_greeting_words += 1\n",
    "    \n",
    "    df_row = pd.DataFrame({\"semantic_score\": score, \"positive_words\": num_positive_words, \"negative_words\": num_negative_words, \"named_entities\": num_named_entities, \"greeting_words\": num_greeting_words}, index=[0])\n",
    "    df_semantics = df_semantics.append(df_row, ignore_index=True)\n",
    "    \n",
    "df_semantics['temp'] = 1\n",
    "\n",
    "for i in range(df_sample['user'].count()):\n",
    "    df_semantics['temp'][i] = i\n",
    "    \n",
    "df_sample = pd.merge(df_sample, df_semantics, on=['temp'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting syntactic based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\faraa\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df_syntactic = pd.DataFrame()\n",
    "\n",
    "for index, row in df_sample.iterrows():\n",
    "    pos_list = []\n",
    "    function_pos_list = [\"PRON\", \"DET\", \"ADP\", \"CONJ\", \"AUX\", \"INTJ\", \"PART\", \"CCONJ\", \"PART\"]\n",
    "    nr_function = 0\n",
    "    sum_length_np = 0\n",
    "    avg_length_np = 0\n",
    "    np_list = []\n",
    "\n",
    "    for token in row['doc']:\n",
    "        pos_list.append(token.pos_)\n",
    "    for pos in pos_list:\n",
    "        if pos in function_pos_list:\n",
    "            nr_function += 1\n",
    "    for np in row['doc'].noun_chunks:\n",
    "        sum_length_np += len(np.text)\n",
    "        np_list.append(np.text)\n",
    "    if len(np_list) > 0:\n",
    "        avg_length_np = sum_length_np/len(np_list)\n",
    "    else:\n",
    "        avg_length_np = 0\n",
    "\n",
    "    df_row = pd.DataFrame({\"nr_pos\": len(set(pos_list)), \"nr_function\": nr_function, \"avg_length_np\": avg_length_np}, index=[0])\n",
    "    df_syntactic = df_syntactic.append(df_row, ignore_index=True)\n",
    "    \n",
    "df_syntactic['temp'] = 1\n",
    "\n",
    "for i in range(df_sample['user'].count()):\n",
    "    df_syntactic['temp'][i] = i\n",
    "    \n",
    "df_sample = pd.merge(df_sample, df_syntactic, on=['temp'])\n",
    "df_sample = df_sample.drop('temp', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      Message-ID  \\\n",
      "0  <11669066.1075861668701.JavaMail.evans@thyme>   \n",
      "1  <23478641.1075857656601.JavaMail.evans@thyme>   \n",
      "2  <24148824.1075857583291.JavaMail.evans@thyme>   \n",
      "3   <5634476.1075852716955.JavaMail.evans@thyme>   \n",
      "4   <4918911.1075857613017.JavaMail.evans@thyme>   \n",
      "\n",
      "                                             content      user  \\\n",
      "0  \\nYOU HAVE ACCESS TO COME IN THE BUILDING ON S...  arnold-j   \n",
      "1               can you change #23 and #375 to Nymex  arnold-j   \n",
      "2  hey podner:\\nwhere are you buying me dinner to...  arnold-j   \n",
      "3  with?\\n\\n -----Original Message-----\\nFrom: \\t...  arnold-j   \n",
      "4  fine\\n\\n\\nFrom: Sarah Wesner/ENRON@enronXgate ...  arnold-j   \n",
      "\n",
      "                                                 doc  chars  letters  \\\n",
      "0  (\\n, YOU, HAVE, ACCESS, TO, COME, IN, THE, BUI...    288      238   \n",
      "1  (can, you, change, #, 23, and, #, 375, to, Nymex)     29       22   \n",
      "2  (hey, podner, :, \\n, where, are, you, buying, ...     44       41   \n",
      "3  (with, ?, \\n\\n , -----Original, Message-----, ...    285      193   \n",
      "4  (fine, \\n\\n\\n, From, :, Sarah, Wesner, /, ENRO...    409      347   \n",
      "\n",
      "   upper_case  lower_case  punctuations  spaces  ...  \\\n",
      "0         188          50            10      13  ...   \n",
      "1           1          21             2       0  ...   \n",
      "2           0          41             2       1  ...   \n",
      "3          34         159            46      28  ...   \n",
      "4          33         314            24      20  ...   \n",
      "\n",
      "   avg_sentences_per_paragrapgh  avg_words_per_paragraph  semantic_score  \\\n",
      "0                      6.000000                28.000000          0.7695   \n",
      "1                      1.000000                 6.000000          0.0000   \n",
      "2                      2.000000                 9.000000          0.0000   \n",
      "3                      3.000000                 7.600000          0.0000   \n",
      "4                      3.333333                25.333333          0.7184   \n",
      "\n",
      "   positive_words  negative_words  named_entities  greeting_words  nr_pos  \\\n",
      "0               0               0              19               0      11   \n",
      "1               0               0               5               0       7   \n",
      "2               0               0               1               0       8   \n",
      "3               0               0              29               0       9   \n",
      "4               0               1              27               0      15   \n",
      "\n",
      "   nr_function  avg_length_np  \n",
      "0           24      10.047619  \n",
      "1            3       4.000000  \n",
      "2            4       5.250000  \n",
      "3            7       6.850000  \n",
      "4           30       8.714286  \n",
      "\n",
      "[5 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "print (df_sample.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Message-ID', 'content', 'user', 'doc', 'chars', 'letters',\n",
      "       'upper_case', 'lower_case', 'punctuations', 'spaces', 'nums', 'words',\n",
      "       'avg_letters_per_word', 'longwords', 'stopwords', 'TTR', 'HTR',\n",
      "       'max_frequency', 'sentences', 'avg_num_words_per_sentence',\n",
      "       'std_num_words_per_sentence', 'dots', 'commas', 'question_marks',\n",
      "       'exclamations', 'hyphens', 'colons', 'semicolons', 'paragraphs',\n",
      "       'avg_sentences_per_paragrapgh', 'avg_words_per_paragraph',\n",
      "       'semantic_score', 'positive_words', 'negative_words', 'named_entities',\n",
      "       'greeting_words', 'nr_pos', 'nr_function', 'avg_length_np'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print (df_sample.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['user'] = df_sample['user'].map( {'arnold-j':1, 'bass-e':2, 'farmer-d':3, 'germany-c':4, 'jones-t':5, 'lenhart-m':6, 'lokay-m':7, 'love-p':8, 'mann-k':9, 'nemec-g':10, 'perlingiere-d':11, 'rogers-b':12, 'scott-s':13, 'symes-k':14} ).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user  chars  letters  upper_case  lower_case  punctuations  spaces  nums  \\\n",
      "0     1    288      238         188          50            10      13    27   \n",
      "\n",
      "   words  avg_letters_per_word  ...  avg_sentences_per_paragrapgh  \\\n",
      "0     56                  4.25  ...                           6.0   \n",
      "\n",
      "   avg_words_per_paragraph  semantic_score  positive_words  negative_words  \\\n",
      "0                     28.0          0.7695               0               0   \n",
      "\n",
      "   named_entities  greeting_words  nr_pos  nr_function  avg_length_np  \n",
      "0              19               0      11           24      10.047619  \n",
      "\n",
      "[1 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "df_sample.drop(['doc', 'content', 'Message-ID'], axis=1, inplace=True)\n",
    "print (df_sample.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 36)\n",
      "(28, 36)\n"
     ]
    }
   ],
   "source": [
    "df_sample.index = list(range(len(df_sample.index)))\n",
    "\n",
    "train_idx, test_idx= train_test_split(df_sample.index, test_size=0.2, random_state=42) \n",
    "train_df = df_sample.iloc[train_idx]\n",
    "test_df = df_sample.iloc[test_idx]\n",
    "\n",
    "print (train_df.shape)\n",
    "print (test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "X = train_df.drop('user', axis=1)\n",
    "y = train_df.user\n",
    "\n",
    "print (X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "sScaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "\n",
    "XScaled = minmax_scale((sScaler.fit_transform(X)), feature_range=(0, 1))\n",
    "y_label = label_binarize(y, classes=list(range(1,13)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.drop('user', axis=1)\n",
    "y_test = test_df.user\n",
    "X_test_Scaled = minmax_scale((sScaler.fit_transform(X_test)), feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc: nan (+/- nan)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\faraa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: bad input shape (89, 12)\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\faraa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: bad input shape (89, 12)\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\faraa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: bad input shape (90, 12)\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\faraa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: bad input shape (90, 12)\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\faraa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: bad input shape (90, 12)\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf')\n",
    "scores = cross_val_score(clf, XScaled, y_label, cv=5, scoring='roc_auc')\n",
    "print(\"roc_auc: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.14286"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(kernel='rbf')\n",
    "svc.fit(X, y)\n",
    "y_pred = svc.predict(X_test)\n",
    "acc_svc = round(svc.score(X_test, y_test) * 100, 5)\n",
    "acc_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-d591e5ce5967>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ball_tree'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXScaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'roc_auc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"roc_auc: %0.4f (+/- %0.4f)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    388\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    391\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 236\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1002\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1003\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    542\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 544\u001b[1;33m         \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    545\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer)\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m     error_msg = (\"scoring must return a number, got %s (%s) \"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_BaseScorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m                 score = scorer._score(cached_call, estimator,\n\u001b[1;32m---> 87\u001b[1;33m                                       *args, **kwargs)\n\u001b[0m\u001b[0;32m     88\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m                 \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(self, method_caller, clf, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    330\u001b[0m                                                  **self._kwargs)\n\u001b[0;32m    331\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sign\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_score_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_factory_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    393\u001b[0m                                              max_fpr=max_fpr),\n\u001b[0;32m    394\u001b[0m                                      \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m                                      sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0my_score_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnot_average_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         score[c] = binary_metric(y_true_c, y_score_c,\n\u001b[1;32m--> 120\u001b[1;33m                                  sample_weight=score_weight)\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;31m# Average the results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[1;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[1;34m\"\"\"Binary roc auc score\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m         raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\u001b[0m\u001b[0;32m    222\u001b[0m                          \"is not defined in that case.\")\n\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors = 50,algorithm='ball_tree')\n",
    "scores = cross_val_score(clf, XScaled, y_label, cv=5, scoring='roc_auc')\n",
    "print(\"roc_auc: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 100,weights ='distance')\n",
    "knn.fit(X, y)\n",
    "y_pred = knn.predict(X_test)\n",
    "acc_knn = round(knn.score(X_test, y_test) * 100, 5)\n",
    "acc_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100) \n",
    "scores = cross_val_score(clf, X, y_label, cv=5, scoring='roc_auc')\n",
    "print(\"roc_auc: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X, y)\n",
    "Y_pred = random_forest.predict(X_test)\n",
    "acc_random_forest = round(random_forest.score(X_test, y_test) * 100, 5)\n",
    "acc_random_forest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
